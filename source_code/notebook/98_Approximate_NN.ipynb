{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aproximate Nearest Neighbor from Scratch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Next : \n",
    "2. Add priority queue for predict function\n",
    "3. based on max distance from every node"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-24 14:10:07.056225: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-24 14:10:08.079811: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-24 14:10:08.122220: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-06-24 14:10:08.122302: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-06-24 14:10:09.844414: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-24 14:10:09.844699: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-24 14:10:09.844712: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-24 14:10:11.408351: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-06-24 14:10:11.408765: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-06-24 14:10:11.408913: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (SAT-PC): /proc/driver/nvidia/version does not exist\n",
      "2023-06-24 14:10:11.410527: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# import basic library for data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# import sys library \n",
    "# and append src folder into path\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "# import approximate_nn and knn library\n",
    "from src.approximate_nn import ApproximateNearestNeighbor\n",
    "from src.approximate_nn import KNearestNeighbor\n",
    "\n",
    "# import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import word embedding model\n",
    "import tensorflow as tf\n",
    "embedding = tf.keras.models.load_model(\"../../model/nnlm-id-dim50/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN Before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree:\n",
    "    def __init__(self,\n",
    "                 children_left = None,\n",
    "                 children_right = None,\n",
    "                 size : int = None,\n",
    "                 is_leaf : bool = None,\n",
    "                 hyperplane : np.array = None,\n",
    "                 data_registered : np.array = None,\n",
    "                 label_registered : np.array = None):\n",
    "        \"\"\"Class for store Node\n",
    "\n",
    "        Args:\n",
    "            children_left (Tree, optional): \n",
    "                Tree for data left. Defaults to None.\n",
    "            children_right (_type_, optional): \n",
    "                Tree for data right. Defaults to None.\n",
    "            size (int, optional): \n",
    "                Count of data point in a tree. Defaults to None.\n",
    "        \"\"\"\n",
    "        self.children_left = children_left\n",
    "        self.children_right = children_right\n",
    "        self.size = size\n",
    "        self.is_leaf = is_leaf\n",
    "        self.hyperplane = hyperplane\n",
    "        self.data_registered = data_registered\n",
    "        self.label_registered = label_registered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApproximateNearestNeighborOld:\n",
    "    def __init__(self,\n",
    "                 min_sample_per_branch : int = 10,\n",
    "                 distance_type : str = \"eucledian\"):\n",
    "        self.min_sample_per_branch = min_sample_per_branch\n",
    "        self.distance_type = distance_type\n",
    "\n",
    "    def create_index(self,\n",
    "                     X : np.array,\n",
    "                     y : np.array) -> None :\n",
    "        # Pass the data by value\n",
    "        X = np.array(X).copy()\n",
    "        y = np.array(y).copy()\n",
    "\n",
    "        # Grow indexing Tree\n",
    "        self.forest = self.create_forest(X, y, 10)\n",
    "\n",
    "    def create_forest(self,\n",
    "                    X : np.array,\n",
    "                    y : np.array,\n",
    "                    n_tree : int = 10) -> np.array :\n",
    "        # prepare the container object\n",
    "        trees = []\n",
    "\n",
    "        for i in range(n_tree):\n",
    "            tree = self.grow_index(X,y)\n",
    "            trees.append(tree)\n",
    "        \n",
    "        return trees\n",
    "\n",
    "    def grow_index(self,\n",
    "                   X : np.array,\n",
    "                   y : np.array,\n",
    "                   depth : int = 0):\n",
    "        # calculate node size\n",
    "        node_size = len(X)\n",
    "\n",
    "        # if the node size larger than minimum data\n",
    "        if node_size > self.min_sample_per_branch:\n",
    "\n",
    "            # create Tree object without\n",
    "            # registering data\n",
    "            node = Tree(size = node_size, is_leaf = False)\n",
    "\n",
    "            # split the node\n",
    "            # and calculate hyperplane parameter\n",
    "            X_left, X_right, y_left, y_right, hyperplane = self.hyperplane_split(X, y)\n",
    "            node.hyperplane = hyperplane\n",
    "\n",
    "            # grow recursively the branch\n",
    "            node.children_left = self.grow_index(X_left, y_left, depth+1)\n",
    "            node.children_right = self.grow_index(X_right, y_right, depth+1)\n",
    "        \n",
    "        else :\n",
    "            # create Tree object with\n",
    "            # registered data\n",
    "            node = Tree(size=node_size,\n",
    "                        is_leaf = True,\n",
    "                        data_registered = X,\n",
    "                        label_registered = y,\n",
    "                        hyperplane=None)\n",
    "            \n",
    "        return node\n",
    "    \n",
    "    def hyperplane_split(self,\n",
    "                         X : np.array,\n",
    "                         y :np.array):\n",
    "\n",
    "        # pick 2 random data point from data using\n",
    "        random_index = np.random.randint(low=0, high=len(X)-1, size=2)\n",
    "        random_point = X[random_index]\n",
    "\n",
    "        # calculate the middle point\n",
    "        random_middle = np.sum(random_point, axis=0)/2\n",
    "\n",
    "        # vector random point\n",
    "        vector = random_point[0] - random_point[1]\n",
    "\n",
    "        # Create the hyperplane equation\n",
    "        c = -np.dot(vector,random_middle)\n",
    "        hyperplane = np.append(vector, c)\n",
    "\n",
    "        # calculate the sign for every data \n",
    "        result_sign = np.sign(np.dot(X, hyperplane[:-1].T) + hyperplane[-1])\n",
    "\n",
    "        # separate the data into left and right data\n",
    "        X_left = X[np.where(result_sign==-1)]\n",
    "        X_right = X[np.where(result_sign==1)]\n",
    "        y_left = y[np.where(result_sign==-1)]\n",
    "        y_right = y[np.where(result_sign==1)]\n",
    "\n",
    "        return X_left, X_right, y_left, y_right, hyperplane\n",
    "    \n",
    "    def find_items_forest(self,\n",
    "                          X_in : np.array,\n",
    "                          n_items : int = 10):\n",
    "\n",
    "        # crate empty container for store \n",
    "        # item from each tree with feature \n",
    "        # of X plus 1 for y\n",
    "        item_forest = np.empty((0,X_in.shape[1]+1), dtype=float)\n",
    "\n",
    "        # populate data from leaf\n",
    "        for tree in self.forest:\n",
    "            item_tree = self.find_item_leaf(X_in, tree=tree)\n",
    "            item_forest = np.append(item_forest, item_tree, axis=0)\n",
    "\n",
    "        # eliminate duplicate data\n",
    "        item_forest = np.unique(item_forest, axis=0)\n",
    "        \n",
    "        # separate the item feature and item_label\n",
    "        X_forest = item_forest[:,:X_in.shape[1]].astype('float')\n",
    "        y_forest = item_forest[:,-1]\n",
    "\n",
    "        # rank the X_env and retrieve the y\n",
    "        ranked_index = self.rank_neighbors(X_in,X_forest)\n",
    "        \n",
    "        \n",
    "        if len(ranked_index) < n_items:\n",
    "            return y_forest[ranked_index]\n",
    "        else:\n",
    "            return y_forest[ranked_index[:n_items]]\n",
    "        \n",
    "    def find_item_leaf(self,\n",
    "                  X_in : np.array,\n",
    "                  tree):\n",
    "        \n",
    "        if tree.is_leaf:\n",
    "            return np.column_stack((tree.data_registered, tree.label_registered))\n",
    "        \n",
    "        else:\n",
    "            sign_check = np.sign(np.dot(X_in, tree.hyperplane[:-1]) + tree.hyperplane[-1])\n",
    "            if sign_check == 1:\n",
    "                branch = tree.children_right\n",
    "            else:\n",
    "                branch = tree.children_left\n",
    "            return self.find_item_leaf(X_in, branch)\n",
    "        \n",
    "    \n",
    "    def rank_neighbors(self,\n",
    "                         X_in : np.array,\n",
    "                         X_env : np.array) -> np.array :\n",
    "        \"\"\"Method to compute distance between data input\n",
    "           and registered data in a leaf, then rank the \n",
    "           environment\n",
    "\n",
    "        Args:\n",
    "            X_in (np.array) (k,):\n",
    "                Data input into the environment with 1 \n",
    "                data point and k number of feature\n",
    "            X_env (np.array) (n,k):\n",
    "                Data registered in the environment with\n",
    "                n data point registered in the environment\n",
    "                and k number of feature\n",
    "\n",
    "        Returns:\n",
    "            np.array (n,): \n",
    "                array of index of nearest item calculated \n",
    "                between the input and environment data \n",
    "                with size n data index\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.distance_type == \"eucledian\":\n",
    "            distance = np.linalg.norm(X_env - X_in, axis=1)\n",
    "            rank_index = np.argsort(distance)\n",
    "\n",
    "        elif self.distance_type == \"manhattan\":\n",
    "            distance = np.sum(np.abs(X_env - X_in), axis=1)\n",
    "            rank_index = np.argsort(distance)\n",
    "\n",
    "        elif self.distance_type == \"cosine-similarity\":\n",
    "            distance = np.squeeze(X_env @ X_in.T)/(np.linalg.norm(X_env, axis=1)*np.linalg.norm(X_in))\n",
    "            rank_index = np.argsort(-distance)\n",
    "\n",
    "        else:\n",
    "            distance = np.squeeze(X_env @ X_in.T)\n",
    "            rank_index = np.argsort(-distance)\n",
    "\n",
    "        return rank_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49424474 0.55992359 0.34487469 0.26941805 0.96149909] 347\n"
     ]
    }
   ],
   "source": [
    "X = np.random.rand(100,5)\n",
    "y = np.random.randint(low=100, high=1000, size=100)\n",
    "y2 = y_train.sample(100, random_state=666).values.astype('str')\n",
    "\n",
    "print(X[0], y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ApproximateNearestNeighborOld(min_sample_per_branch=10)\n",
    "model.create_index(X, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['leksikolog', 'neoimpresionisme', 'kanung', 'kenali asam bawah',\n",
       "       'tebing penyamun', 'kuala', 'soakonora', 'manurungnge',\n",
       "       'sondo-sondo', 'kaliajir'], dtype='<U32')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.find_items_forest(np.array([[0.19798236,0.35213506,0.34625828,0.71753865,0.53268257]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "model.tree.children_left.children_left.children_left.children_right.hyperplane"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 93566 entries, 0 to 93565\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   words      93566 non-null  object\n",
      " 1   embedding  93566 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# import embedding data\n",
    "embedding_data = joblib.load(\"../../data/processed/word_embedding.pkl\")\n",
    "embedding_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create train and test data\n",
    "X = embedding_data['embedding']\n",
    "y = embedding_data['words']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.01, random_state=666)\n",
    "\n",
    "# save training and test data\n",
    "joblib.dump(X_train, \"../../data/processed/X_train.pkl\")\n",
    "joblib.dump(X_test, \"../../data/processed/X_test.pkl\")\n",
    "joblib.dump(y_train, \"../../data/processed/y_train.pkl\")\n",
    "joblib.dump(y_test, \"../../data/processed/y_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pickle data\n",
    "X_train = joblib.load(\"../../data/processed/X_train.pkl\")\n",
    "X_test = joblib.load(\"../../data/processed/X_test.pkl\")\n",
    "y_train = joblib.load(\"../../data/processed/y_train.pkl\")\n",
    "y_test = joblib.load(\"../../data/processed/y_test.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Model Training / Registering Data Into Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.1. ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_model = ApproximateNearestNeighbor(min_size_split=100, distance_type=\"cosine-similarity\", n_tree = 5)\n",
    "ann_model.fit(X = np.array(X_train.to_numpy().tolist()), y=y_train.values.astype('str'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.2. KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNearestNeighbor(distance_type=\"cosine-similarity\")\n",
    "knn_model.fit(X = np.array(X_train.to_numpy().tolist()), y=y_train.values.astype('str'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Model Testing / Searching Similar Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_similar_item(embedding_model : object,\n",
    "                        neighbors_model : object,\n",
    "                        text_input : str):\n",
    "    # generate embedding for text input\n",
    "    input_embed = embedding_model([text_input]).numpy().squeeze().tolist()\n",
    "\n",
    "    # search neighbors by embedding \n",
    "    similar_item = neighbors_model.find_similar_items(np.array([input_embed]))\n",
    "\n",
    "    return similar_item"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.1. ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['kucing', 'angsa', 'ular', 'anjing', 'monyet', 'buaya', 'jerapah',\n",
       "       'musang', 'kobra', 'koala'], dtype='<U44')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_item = search_similar_item(embedding_model=embedding, neighbors_model=ann_model, text_input=\"kucing\")\n",
    "sim_item"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.2. KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['kucing', 'angsa', 'ular', 'anjing', 'batu kucing', 'monyet',\n",
       "       'kelinci', 'binatang', 'beruang', 'sumur kucing'], dtype='<U44')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_item_ = search_similar_item(embedding_model=embedding, neighbors_model=knn_model, text_input=\"kucing\")\n",
    "sim_item_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Searching Time Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.5 ms ± 775 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "sim_item = search_similar_item(embedding_model=embedding, neighbors_model=ann_model, text_input=\"kucing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.5 ms ± 705 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "sim_item_ = search_similar_item(embedding_model=embedding, neighbors_model=knn_model, text_input=\"kucing\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
