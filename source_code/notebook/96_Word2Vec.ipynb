{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-25 06:40:32.866542: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-25 06:40:33.804258: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-25 06:40:33.907619: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-06-25 06:40:33.907696: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-06-25 06:40:36.517940: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-25 06:40:36.518152: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-25 06:40:36.518165: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Model Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-24 21:38:01.267190: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-06-24 21:38:01.267310: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-06-24 21:38:01.267368: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (SAT-PC): /proc/driver/nvidia/version does not exist\n",
      "2023-06-24 21:38:01.268701: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "No sentence-transformers model found with name ../../model/indobert-base-uncased. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "embedding_nnlm = tf.keras.models.load_model(\"../../model/nnlm-id-dim50/\")\n",
    "embedding_indobert = SentenceTransformer(\"../../model/indobert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_text_nnlm(model : object, \n",
    "               text : str) -> list :\n",
    "    \"\"\"Function to create embedding \n",
    "        using model object\n",
    "\n",
    "    Args:\n",
    "        model (object): Embedding model\n",
    "        text (str): text input\n",
    "\n",
    "    Returns:\n",
    "        list: embedding of the text input\n",
    "    \"\"\"\n",
    "    try :\n",
    "        embedding_list = model([text]).numpy().squeeze().tolist()\n",
    "        return embedding_list\n",
    "    except : \n",
    "        print(f\"The error text is : {text}\")\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vetorize Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Source : \n",
    "- https://github.com/kirralabs/indonesian-NLP-resources\n",
    "- https://github.com/sastrawi/sastrawi/blob/master/data/kata-dasar.original.txt\n",
    "- https://github.com/edwardsamuel/Wilayah-Administratif-Indonesia/tree/master/csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 93566 entries, 0 to 93565\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   words   93566 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 731.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "district_data = pd.read_csv(\"../../data/raw/districts.csv\", header=None)\n",
    "province_data = pd.read_csv(\"../../data/raw/provinces.csv\", header=None)\n",
    "regencies_data = pd.read_csv(\"../../data/raw/regencies.csv\", header=None)\n",
    "villages_data = pd.read_csv(\"../../data/raw/villages.csv\", header=None)\n",
    "kata_data = pd.read_table(\"../../data/raw/kata-dasar.original.txt\", header=None)\n",
    "\n",
    "# format data\n",
    "district_data = district_data[2].apply(lambda x: x.lower())\n",
    "province_data = province_data[1].apply(lambda x: x.lower())\n",
    "regencies_data = regencies_data[2].apply(lambda x: x.lower())\n",
    "villages_data = villages_data[2].apply(lambda x: x.lower())\n",
    "\n",
    "# concat data\n",
    "dataset = pd.concat([district_data, province_data, regencies_data, villages_data, kata_data], axis=0)\n",
    "dataset.columns = [\"words\"]\n",
    "dataset.drop_duplicates(inplace=True)\n",
    "dataset.dropna(inplace=True)\n",
    "dataset.reset_index(drop=True, inplace=True)\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aba-aba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30337</th>\n",
       "      <td>zulmat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30338</th>\n",
       "      <td>zulu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30339</th>\n",
       "      <td>zurafah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30340</th>\n",
       "      <td>zuriah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30341</th>\n",
       "      <td>zus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30342 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0            a\n",
       "1           ab\n",
       "2          aba\n",
       "3      aba-aba\n",
       "4         abad\n",
       "...        ...\n",
       "30337   zulmat\n",
       "30338     zulu\n",
       "30339  zurafah\n",
       "30340   zuriah\n",
       "30341      zus\n",
       "\n",
       "[30342 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create embedding nnlm\n",
    "dataset_nnlm = dataset.copy()\n",
    "dataset_nnlm['embedding'] = dataset_nnlm['words'].apply(lambda x : embed_text_nnlm(model=embedding_nnlm, text=x))\n",
    "joblib.dump(dataset_nnlm,\"../../data/processed/word_embedding_nnlm.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30342 entries, 0 to 30341\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   words   30341 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 237.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# create embedding indobert\n",
    "dataset_indobert = kata_data.copy()\n",
    "dataset_indobert.columns = ['words']\n",
    "dataset_indobert.drop_duplicates(inplace=True)\n",
    "dataset_indobert.dropna(inplace=True)\n",
    "dataset_indobert.reset_index(drop=True, inplace=True)\n",
    "dataset_indobert.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_indobert(model, text) :\n",
    "    try :\n",
    "        return model.encode(text).tolist()\n",
    "    except :\n",
    "        print(f\"Text causing error : {text}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text causing error : nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../../data/processed/word_embedding_indobert.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_indobert['embedding'] = dataset_indobert['words'].apply(lambda x : embed_indobert(model=embedding_indobert, text=x))\n",
    "joblib.dump(dataset_indobert, \"../../data/processed/word_embedding_indobert.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
