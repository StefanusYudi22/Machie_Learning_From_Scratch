{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  4, -3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = np.array([[0.2,0.3,0.4],\n",
    "              [0.1,0.1,0.1]])\n",
    "\n",
    "e  = np.array([1,2,4])\n",
    "c = -3\n",
    "np.append(e, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_class = SomeClass(n=10)\n",
    "\n",
    "T_ensemble = [copy.deepcopy(T_class) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_sample_indices(seed, n_estimators, n_population, n_samples, bootstrap=True):\n",
    "    \"\"\"\n",
    "    Generate the Bootstrapped samples indices\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    seed : int\n",
    "        The random seed\n",
    "\n",
    "    n_estimators : int\n",
    "        The number of bootstrapped samples were to generate\n",
    "\n",
    "    n_population : int\n",
    "        The number of maximum samples available\n",
    "\n",
    "    n_samples : int\n",
    "        The number of samples to generate in each bootstrapped samples\n",
    "\n",
    "    bootstrap : bool, default=True\n",
    "        The bootstrap condition\n",
    "        If `True`, you do the sampling WITH REPLACEMENT\n",
    "        Else, you do the sampling WITHOUT REPLACEMENT\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sample_indices : {array-like} of shape (n_estimators, n_samples)\n",
    "        The bootstrapped sample indices\n",
    "    \"\"\"\n",
    "    # Get the seed\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Get the bagging indices\n",
    "    sample_indices = np.random.choice(n_population,\n",
    "                                      size = (n_estimators, n_samples),\n",
    "                                      replace = bootstrap)\n",
    "    \n",
    "    return sample_indices\n",
    "\n",
    "def _generate_feature_indices(seed, n_estimators, n_population, n_features, bootstrap=False):\n",
    "    \"\"\"\n",
    "    Generate the Bootstrapped samples indices\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    seed : int\n",
    "        The random seed\n",
    "\n",
    "    n_estimators : int\n",
    "        The number of bootstrapped samples were to generate\n",
    "\n",
    "    n_samples : int\n",
    "        The number of samples to generate in each bootstrapped samples\n",
    "\n",
    "    bootstrap : bool, default=False\n",
    "        The bootstrap condition\n",
    "        If `True`, you do the sampling WITH REPLACEMENT\n",
    "        Else, you do the sampling WITHOUT REPLACEMENT\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    feature_indices : {array-like} of shape (n_estimators, n_feature)\n",
    "        The bootstrapped sample indices\n",
    "    \"\"\"\n",
    "    # Get the seed\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Get the bagging indices\n",
    "    feature_indices = np.empty((n_estimators, n_features), dtype=\"int\")\n",
    "    for i in range(n_estimators):\n",
    "        feature_indices[i] = np.random.choice(n_population, \n",
    "                                              n_features, \n",
    "                                              replace=bootstrap)\n",
    "        feature_indices[i].sort()\n",
    "\n",
    "    return feature_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 3],\n",
       "       [0, 3, 4],\n",
       "       [0, 1, 4]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_generate_feature_indices(seed=666, n_estimators=3, n_population=5, n_features=3, bootstrap=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 1, 0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(4, size = 4, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Log_Loss(y : np.array) -> float:\n",
    "    \"\"\"Calculate impurity of a node using Log Loss\n",
    "\n",
    "    Args:\n",
    "        y (np.array) (n,):\n",
    "            label data in a node\n",
    "\n",
    "    Returns:\n",
    "        float: the impurity of the node\n",
    "    \"\"\"\n",
    "    # Extract class and count of each class\n",
    "    num_data = len(y)\n",
    "    class_, counts = np.unique(y, return_counts=True)\n",
    "    class_counts = dict(zip(class_, counts))\n",
    "    \n",
    "    # Calculate the proportion every class in a node\n",
    "    p_class = {k : class_counts[k]/num_data for k in class_}\n",
    "\n",
    "    # Find the majority class in the node\n",
    "    ind_max = np.argmax(counts)\n",
    "    class_max = class_[ind_max]\n",
    "\n",
    "    # Calculate the node impurity\n",
    "    node_impurity = 1 - p_class[class_max]\n",
    "\n",
    "    return node_impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Entropy(y : np.array) -> float:\n",
    "    \"\"\"Calculate impurity of a node using Entropy\n",
    "\n",
    "    Args:\n",
    "        y (np.array) (n,):\n",
    "            label data in a node\n",
    "\n",
    "    Returns:\n",
    "        float: the impurity of the node\n",
    "    \"\"\"\n",
    "    # Extract class and count of each class\n",
    "    num_data = len(y)\n",
    "    class_, counts = np.unique(y, return_counts=True)\n",
    "    class_counts = dict(zip(class_, counts))\n",
    "    \n",
    "    # Calculate the proportion every class in a node\n",
    "    p_class = {k : class_counts[k]/num_data for k in class_}\n",
    "\n",
    "    # Calculate the node impurity\n",
    "    node_impurity = np.sum([p*np.log(p) for p in p_class.values()])\n",
    "\n",
    "    return -node_impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REGRESSION IMPURITY\n",
    "def MSE(y : np.array) -> float:\n",
    "    \"\"\"Calculate impurity of a node using MSE\n",
    "\n",
    "    Args:\n",
    "        y (np.array) (n,):\n",
    "            target data in a node\n",
    "\n",
    "    Returns:\n",
    "        float: the impurity of the node\n",
    "    \"\"\"\n",
    "    # Calculate the mean of the node\n",
    "    node_mean = np.mean(y)\n",
    "\n",
    "    # Calculate the node-impurity (variance)\n",
    "    node_impurity = np.mean([(y_i - node_mean)**2 for y_i in y])\n",
    "\n",
    "    return node_impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAE(y : np.array) -> float:\n",
    "    \"\"\"Calculate impurity of a node using MAE\n",
    "\n",
    "    Args:\n",
    "        y (np.array) (n,):\n",
    "            target data in a node\n",
    "\n",
    "    Returns:\n",
    "        float: the impurity of the node\n",
    "    \"\"\"\n",
    "    # Calculate the node median\n",
    "    node_median = np.median(y)\n",
    "\n",
    "    # Calculate the node-impurity (variance)\n",
    "    node_impurity = np.mean([np.abs(y_i - node_median) for y_i in y])\n",
    "\n",
    "    return node_impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6311111111111112\n",
      "0.5333333333333333\n",
      "1.0437570363314084\n",
      "0.5155555555555555\n",
      "0.5333333333333333\n"
     ]
    }
   ],
   "source": [
    "y = np.array([1,1,1,1,1,1,1,0,0,0,2,2,2,2,2])\n",
    "print(Gini(y))\n",
    "print(Log_Loss(y))\n",
    "print(Entropy(y))\n",
    "print(MSE(y))\n",
    "print(MAE(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _split_data(data, feature, threshold):\n",
    "    \"\"\"\n",
    "    Split data based on given feature and threshold\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : {array-like}, shape of (n_samples, n_features+1)\n",
    "        sample data X, y\n",
    "\n",
    "    feature: str\n",
    "        feature to split\n",
    "\n",
    "    threshold: float\n",
    "        threshold to split the data\n",
    "        if data[feature] > threshold\n",
    "            return data_right\n",
    "        else:\n",
    "            return data_left\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data_left: {array-like}, shape of (n_samples_1, n_features+1)\n",
    "        X, y data that its X[feature] <= threshold\n",
    "\n",
    "    data_right: {array-like}, shape of (n_samples_2, n_features+1)\n",
    "        X, y data that its X[feature] > threshold\n",
    "    \"\"\"\n",
    "    cond_left = data[:, feature] <= threshold\n",
    "    data_left = data[cond_left]\n",
    "    data_right = data[~cond_left]\n",
    "\n",
    "    return data_left, data_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 3, 3, 3],\n",
       "       [4, 4, 4, 4]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array([[1,2,3,4],\n",
    "                 [1,2,2,2],\n",
    "                 [3,3,3,3],\n",
    "                 [4,4,4,4],\n",
    "                 [1,2,4,3]])\n",
    "cond_left = data[:,1] <= 2\n",
    "data_left = data[cond_left]\n",
    "data_right = data[~cond_left]\n",
    "data_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_possible_split(data):\n",
    "    \"\"\"\n",
    "    Generate possible split threshold\n",
    "    \"\"\"\n",
    "    # Copy data\n",
    "    data = data.copy()\n",
    "\n",
    "    # Extract the unique value\n",
    "    unique_val = np.unique(data)\n",
    "\n",
    "    # Extract shape of unique_val\n",
    "    m = len(unique_val)\n",
    "\n",
    "    # Sort data\n",
    "    unique_val.sort()\n",
    "\n",
    "    # Initialize threshold\n",
    "    threshold = np.zeros(m-1)\n",
    "\n",
    "    # Create the possible split\n",
    "    for i in range(m-1):\n",
    "        val_1 = unique_val[i]\n",
    "        val_2 = unique_val[i+1]\n",
    "\n",
    "        threshold[i] = 0.5*(val_1 + val_2)\n",
    "\n",
    "    return threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5, 2.5, 3.5])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_generate_possible_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at iteration 0 is : 23.304953703703703\n",
      "Cost at iteration 1000 is : 0.252519828805698\n",
      "Cost at iteration 2000 is : 0.2501842947593061\n",
      "Cost at iteration 3000 is : 0.25001347891500847\n",
      "Cost at iteration 4000 is : 0.25000098581831875\n",
      "Cost at iteration 5000 is : 0.2500000721005926\n",
      "Cost at iteration 6000 is : 0.2500000052732794\n",
      "Cost at iteration 7000 is : 0.2500000003856764\n",
      "Cost at iteration 8000 is : 0.2500000000282077\n",
      "Cost at iteration 9000 is : 0.25000000000206307\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "y = np.array([10, 3, 8])\n",
    "X = np.array([[3,3],\n",
    "              [1,1],\n",
    "              [2,2]])\n",
    "\n",
    "w, b = gradient_descent(X, y, 1e-2, 10000, fit_intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.49999956,  3.50000082,  7.00000019])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X @ w + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def gradient_descent(X, y, alpha, num_iters, fit_intercept=True): \n",
    "\n",
    "    # initialize gain and intercept\n",
    "    w = np.zeros(X.shape[1])\n",
    "    b = np.zeros(1)\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "\n",
    "        # Calculate the gradient and update the parameters\n",
    "        err = X@w + b - y\n",
    "\n",
    "        dj_dw = (1/len(X))*np.sum(X*err.reshape(-1,1), axis=0)\n",
    "        w = w - alpha * dj_dw\n",
    "\n",
    "        if fit_intercept == True:\n",
    "            dj_db = (1/len(X))*np.sum(err)\n",
    "            b = b - alpha * dj_db\n",
    "      \n",
    "        if i%(num_iters/10) == 0:\n",
    "            # print cost function\n",
    "            cost = (1/(2*len(X)))*np.sum((X@w + b - y)**2)\n",
    "            print(f\"Cost at iteration {i} is : {cost}\")\n",
    "        \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3,4,5])\n",
    "b = np.array([1])\n",
    "\n",
    "np.append(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost     0.25   \n",
      "Iteration 1000: Cost     0.25   \n",
      "Iteration 2000: Cost     0.25   \n",
      "Iteration 3000: Cost     0.25   \n",
      "Iteration 4000: Cost     0.25   \n",
      "Iteration 5000: Cost     0.25   \n",
      "Iteration 6000: Cost     0.25   \n",
      "Iteration 7000: Cost     0.25   \n",
      "Iteration 8000: Cost     0.25   \n",
      "Iteration 9000: Cost     0.25   \n"
     ]
    }
   ],
   "source": [
    "w, b, _ = gradient_descent(X, y, w, b, compute_cost, compute_derivative, 1e-1, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.4031242374328485"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([4,7,2])\n",
    "B = np.array([3,1,4])\n",
    "\n",
    "np.linalg.norm((A-B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 3],\n",
       "       [1, 1],\n",
       "       [2, 2]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12, 12],\n",
       "       [ 5,  5],\n",
       "       [ 6,  6]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X*err.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.66666667, 7.66666667])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(X*err.reshape(-1,1), axis=0)/len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.66666667, -5.66666667])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w - np.sum(X*err.reshape(-1,1), axis=0)/len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 1, 2],\n",
       "       [3, 1, 2]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 3, 6])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.T@X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66666667 0.33333333]\n",
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "for y in y_target:\n",
    "    print(np.unique(y, return_counts=True)[1]/np.sum(np.unique(y, return_counts=True)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "[[-1.20095990e+16  1.80143985e+16 -6.00479950e+15]\n",
      " [ 2.40191980e+16 -3.60287970e+16  1.20095990e+16]\n",
      " [-1.20095990e+16  1.80143985e+16 -6.00479950e+15]]\n",
      "=====================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2.,  0., -2.],\n",
       "       [ 8.,  0.,  0.],\n",
       "       [ 4.,  0.,  4.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[1,2,3],[2,3,4],[4,5,6]])\n",
    "X_inv = np.linalg.inv(X)\n",
    "\n",
    "print(\"=====================\")\n",
    "print(X_inv)\n",
    "\n",
    "print(\"=====================\")\n",
    "X @ X_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.  0. -2.]\n",
      " [ 8.  0.  0.]\n",
      " [ 4.  0.  4.]]\n"
     ]
    }
   ],
   "source": [
    "# Import required package\n",
    "import numpy as np\n",
    " \n",
    "# Taking a 3 * 3 matrix\n",
    "A = np.array([[1, 2, 3],\n",
    "              [2, 3, 4],\n",
    "              [4, 5, 6]])\n",
    " \n",
    "# Print matrix identity\n",
    "print(A @ np.linalg.inv(A))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
